{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow部分方法介绍\n",
    "\n",
    "* **random_uniform** 函数用来产生一个随机生成的矩阵\n",
    "\n",
    "```python\n",
    "tf.random_uniform(shape, dtype, seed, seed2, name)\n",
    "```\n",
    "\n",
    "    参数说明：\n",
    "\n",
    "    * shape：生成随机矩阵的大小，通常以列表或元组形式给出。例如：shape=(size1, size2)或shape=[size1, size2]\n",
    "\n",
    "    * dtype：生成随机矩阵中值的类型。\n",
    "\n",
    "    * seed：随机数生成的下界。\n",
    "\n",
    "    * seed2：随机数生成的的上界。\n",
    "\n",
    "\n",
    "* **embedding_lookup** 函数用于截取矩阵的某几行\n",
    "\n",
    "```python\n",
    "tf.nn.embedding_lookup(params, ids)\n",
    "```\n",
    "\n",
    "    参数说明：\n",
    "    \n",
    "    * params：截取的目标矩阵。\n",
    "    \n",
    "    * ids：截取行数，通常用列表形式给出。例如要截取params矩阵的第1,2,3行，就应该如下写：ids=[1,2,3]\n",
    "\n",
    "* **truncated_normal** 用于产生一个服从正态分布的矩阵\n",
    "\n",
    "```python\n",
    "tf.truncated_normal(shape, mean, stddev, dtype, seed, name)\n",
    "```\n",
    "\n",
    "    参数说明：\n",
    "    \n",
    "    * shape：矩阵的大小，通常用元组形式给出。例如：shape=(size1, size2)\n",
    "    \n",
    "    * mean：矩阵中均值的大小。\n",
    "    \n",
    "    * stddev：矩阵中标准差。\n",
    "\n",
    "* **variable_scope**用于产生一个类似命名空间的效果，可以起到一个变量隔离的作用\n",
    "\n",
    "```\n",
    "with tf.variable_scope(\"name\", reuse=False) as scope:\n",
    "    a = tf.get_variable(\"var_name\")\n",
    "    scope.reuse_variables()\n",
    "    b = tf.get_variable(\"var_name\")\n",
    "    assert a == b\n",
    "```\n",
    "\n",
    "    参数说明：\n",
    "    \n",
    "    * reuse:在此命名空间中，变量是否可重用，默认为不可重用，若强行重用（无论是在一个scope上下文管理器中，还是在两个同名的上下文管理器中）会引发异常。\n",
    "    \n",
    "* **trainable_variables()**返回所有的variable型的变量，若变量声明中trainable为False的除外\n",
    "\n",
    "```\n",
    "a = tf.Variable(tf.float32, [1])\n",
    "b = tf.get_variable(\"b\", tf.float32, [1], trainable=False)\n",
    "c = tf.trainable_variables()\n",
    "print(c)\n",
    "#<tf.Variable 'a:0' shape=(1) dtype=float32_ref>\n",
    "```\n",
    "\n",
    "* **tf.gradients(y, x)**用于求函数y关于x的梯度，函数y的表达式中一定要有x项，否则会报错。\n",
    "\n",
    "```\n",
    "sess = tf.InteractiveSession()\n",
    "    with tf.variable_scope(\"foo\") as scope:\n",
    "        a = tf.get_variable(\"a\", shape=(10), dtype=tf.int32)\n",
    "        x = tf.constant([1,2,3,4,5,6,7,8,9,10])\n",
    "        b = tf.constant([2,2,2,2,2,2,2,2,2,2])\n",
    "        y = a * x + b * a\n",
    "        sess.run(y, feed_dict={a:[3,3,3,3,3,3,3,3,3,3]})\n",
    "        for item in tf.gradients(y, a):\n",
    "            print(item.eval())\n",
    "#[ 3  4  5  6  7  8  9 10 11 12]\n",
    "```\n",
    "    \n",
    "    参数说明：\n",
    "    \n",
    "    * y：函数表达式变量名。\n",
    "    \n",
    "    * x：需要求梯度的变量。\n",
    "    \n",
    "* **clip_by_global_norm**求一个合适的梯度，以防止梯度爆炸等不好的情况\n",
    "\n",
    "```\n",
    "tf.clip_by_global_norm(grad, max_grad_norm)\n",
    "```\n",
    "\n",
    "    参数说明：\n",
    "    \n",
    "    * grad:梯度，注意这里是tf.gradients求出的梯度张量，该函数在这个张量的基础上做调整。\n",
    "    \n",
    "    * max_grad_norm：一个截取比率。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
